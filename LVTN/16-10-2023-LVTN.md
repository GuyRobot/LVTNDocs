- Try to train BART for text summarize 
	- https://medium.com/@ferlatti.aldo/fine-tuning-a-chat-summarizer-c18625bc817d
	- https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb
	- https://keras.io/examples/nlp/abstractive_summarization_with_bart/
- [x] Reformat text after generated or clean up dataset
- Try to train BART for translation
	- https://pub.towardsai.net/fine-tune-bart-for-translation-on-wmt16-dataset-and-train-new-tokenizer-4d0fbdc4aa2e
	- https://tmramalho.github.io/science/2020/06/10/fine-tune-neural-translation-models-with-mBART/
- Try to train a model for language classification

Datasets:
- https://github.com/VinAIResearch/PhoMT
- https://metatext.io/datasets/iwslt-15-english-vietnamese
- https://huggingface.co/NlpHUST/t5-en-vi-base/blame/main/README.md